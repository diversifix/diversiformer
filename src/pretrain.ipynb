{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretraining: Train the model to just repeat the input sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0\n",
    "EPOCHS = 1\n",
    "CHECKPOINT = \"google/mt5-small\"\n",
    "CHECKPOINT_SHORT = \"mt5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff for running the same notebook locally and on Google Colab for training\n",
    "import sys\n",
    "\n",
    "COLAB_PATH = \"/content/drive/MyDrive/Colab Notebooks/diversiformer/\"\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive  # type: ignore\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    sys.path.append(COLAB_PATH + \"src\")\n",
    "    %pip install transformers datasets sacrebleu sentencepiece carbontracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import read_wiki_sents\n",
    "from datasets import Dataset\n",
    "\n",
    "sents = read_wiki_sents(COLAB_PATH if IN_COLAB else None)\n",
    "data = Dataset.from_dict(dict(x=sents)).train_test_split(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(data):\n",
    "    inputs = [f\"Wiederhole: {d}\" for d in data[\"x\"]]\n",
    "    targets = data[\"x\"]\n",
    "    model_inputs = tokenizer(inputs)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFT5ForConditionalGeneration\n",
    "\n",
    "try:\n",
    "    # load model\n",
    "    model = TFT5ForConditionalGeneration.from_pretrained(\n",
    "        (COLAB_PATH if IN_COLAB else \"../data/\")\n",
    "        + f\"checkpoint_pretrain_{CHECKPOINT_SHORT}_{START_EPOCH}_epochs\"\n",
    "    )\n",
    "except:\n",
    "    print(\"WARNING: Could not load local model.\")\n",
    "    model = TFT5ForConditionalGeneration.from_pretrained(CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamWeightDecay\n",
    "\n",
    "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, model=model, return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_set = tokenized_data[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_test_set = tokenized_data[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = \"\"\"\n",
    "Wiederhole: Die Botanik definiert Bäume als ausdauernde und verholzende Samenpflanzen, die eine dominierende Sprossachse aufweisen, die durch sekundäres Dickenwachstum an Umfang zunimmt. \n",
    "Wiederhole: Diese Merkmale unterscheiden einen Baum von Sträuchern, Farnen, Palmen und anderen verholzenden Pflanzen. \n",
    "Wiederhole: Im Gegensatz zu ihren entwicklungsgeschichtlichen Vorläufern verfügen die meisten Bäume zudem über wesentlich differenziertere Blattorgane, die mehrfach verzweigten Seitentrieben (Lang- und Kurztrieben) entspringen. \n",
    "Wiederhole: Stamm, Äste und Zweige verlängern sich jedes Jahr durch Austreiben von End- und Seitenknospen, verholzen dabei und nehmen kontinuierlich an Umfang zu. \n",
    "Wiederhole: Im Gegensatz zum Strauch ist es besonderes Merkmal der Bäume, dass die Endknospen über die Seitenknospen dominieren (Apikaldominanz) und sich dadurch ein vorherrschender Haupttrieb herausbildet (Akrotonie). \n",
    "\"\"\".strip().split(\n",
    "    \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, model, tokenizer):\n",
    "    tokenized_text = tokenizer.encode(prompt, return_tensors=\"tf\")\n",
    "    summary_ids = model.generate(tokenized_text, max_length=tokenized_text.shape[1])\n",
    "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    import json\n",
    "    from carbontracker.tracker import CarbonTracker\n",
    "\n",
    "    tracker = CarbonTracker(epochs=EPOCHS, verbose=2)\n",
    "    try:\n",
    "        with open(\n",
    "            COLAB_PATH + f\"example_predictions_pretrain_{CHECKPOINT_SHORT}.json\"\n",
    "        ) as f:\n",
    "            example_eval = json.load(f)\n",
    "    except:\n",
    "        example_eval = []\n",
    "    example_eval = []\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        print(f\"Epoch {START_EPOCH + epoch}\")\n",
    "        tracker.epoch_start()\n",
    "        model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=1)\n",
    "        tracker.epoch_end()\n",
    "        example_eval.append(\n",
    "            [\n",
    "                dict(\n",
    "                    epoch=START_EPOCH + epoch,\n",
    "                    prompt=prompt,\n",
    "                    response=generate(prompt, model, tokenizer),\n",
    "                )\n",
    "                for prompt in examples\n",
    "            ]\n",
    "        )\n",
    "        with open(\n",
    "            COLAB_PATH + f\"example_predictions_pretrain_{CHECKPOINT_SHORT}.json\", \"w\"\n",
    "        ) as f:\n",
    "            json.dump(example_eval, f, indent=2, ensure_ascii=False)\n",
    "        if epoch % 1 == 0:\n",
    "            model.save_pretrained(\n",
    "                COLAB_PATH\n",
    "                + f\"checkpoint_pretrain_{CHECKPOINT_SHORT}_{START_EPOCH+epoch}_epochs\"\n",
    "            )\n",
    "            model.save(\n",
    "                COLAB_PATH\n",
    "                + f\"tf_checkpoint_pretrain_{CHECKPOINT_SHORT}_{START_EPOCH+epoch}_epochs\"\n",
    "            )\n",
    "    tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sents[:20]:\n",
    "    prompt = f\"Wiederhole: {s}\"\n",
    "    output = generate(prompt, model, tokenizer)\n",
    "    print(prompt[12:] == output)\n",
    "    if not (prompt[12:] == output):\n",
    "        print(prompt[12:])\n",
    "        print(output)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
